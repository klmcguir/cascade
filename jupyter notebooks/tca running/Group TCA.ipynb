{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouped TCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensortools as tt\n",
    "import numpy as np\n",
    "import flow\n",
    "from flow.misc import wordhash\n",
    "import pool\n",
    "import pandas as pd\n",
    "import os\n",
    "from cascade import utils\n",
    "from cascade import paths\n",
    "from cascade import tca\n",
    "from copy import deepcopy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse='OA27'\n",
    "tags='naive'\n",
    "run_type='training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dprime_threhsold = 2\n",
    "if dprime_threhsold:\n",
    "    print('yes')\n",
    "dprime = []\n",
    "for day1 in days:\n",
    "    print(pool.calc.behavior.dprime(day1))\n",
    "    dprime.append(pool.calc.behavior.dprime(day1))\n",
    "# days = days[dprime > dprime_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = flow.metadata.RunSorter.frommeta(mice=[mouse], run_types=run_type, tags=tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Run(mouse='OA27', date=170116, run=3, run_type='training', tags=('hungry', 'kelly', 'naive')),\n",
       " Run(mouse='OA27', date=170118, run=3, run_type='training', tags=('hungry', 'kelly', 'naive')),\n",
       " Run(mouse='OA27', date=170119, run=1, run_type='training', tags=('hungry', 'kelly', 'naive'))]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs[0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "44.0\n",
      "1491.0\n"
     ]
    }
   ],
   "source": [
    "# days = flow.metadata.DateSorter.frommeta(mice=[mouse], tags=tags)\n",
    "\n",
    "# # maybe use a run sorter?\n",
    "\n",
    "# dprime pool.calc.behavior.dprime(day1)\n",
    "# pool.calc.driven.trial(day1, dcs)\n",
    "run_list = []\n",
    "for c, run in enumerate(runs[0:-1]):\n",
    "    dfr = tca._triggerfromrun(run)\n",
    "#     dfr = dfr.reset_index()[['trial_idx', 'cell_idx', 'timestamp', 'trace']]\n",
    "#     dfr.rename(columns={'trace': 'trace_' + str(c)}, inplace=True)\n",
    "    run_list.append(dfr)\n",
    "dfr = pd.concat(run_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>trace</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mouse</th>\n",
       "      <th>date</th>\n",
       "      <th>run</th>\n",
       "      <th>trial_idx</th>\n",
       "      <th>cell_idx</th>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">OA27</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">170116</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">3</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>-1.0</th>\n",
       "      <td>-0.078952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>-1.0</th>\n",
       "      <td>-0.024965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>-1.0</th>\n",
       "      <td>0.057309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>-1.0</th>\n",
       "      <td>-0.248164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>-1.0</th>\n",
       "      <td>0.101081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  trace\n",
       "mouse date   run trial_idx cell_idx timestamp          \n",
       "OA27  170116 3   0.0       1.0      -1.0      -0.078952\n",
       "                 1.0       1.0      -1.0      -0.024965\n",
       "                 2.0       1.0      -1.0       0.057309\n",
       "                 3.0       1.0      -1.0      -0.248164\n",
       "                 4.0       1.0      -1.0       0.101081"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build list of cells with their ids and then do an outer merge of the dataframes\n",
    "times = len(np.unique(dfr.reset_index()['timestamp']))\n",
    "test = dfr.pivot_table(\n",
    "            index=['date', 'run', 'cell_idx'],\n",
    "            columns=['trial_idx', 'timestamp'], values='trace')\n",
    "\n",
    "for d in np.unique(test.reset_index()['date']):\n",
    "    keep = np.where((test.reset_index()['date'] == d) == True)[0]\n",
    "    df_today = test.iloc[keep, :]\n",
    "    for r in np.unique(df_today.reset_index()['run']):\n",
    "        keep2 = np.where((df_today.reset_index()['run'] == r) == True)[0]\n",
    "        df_run = df_today.iloc[keep2, :]\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(264, 16816)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(times)\n",
    "mat = df_run.values\n",
    "np.shape(mat)\n",
    "# np.shape(df_run.values.reshape((np.shape(df_run)[0], times, -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(754, 16816)\n",
      "(754,)\n"
     ]
    }
   ],
   "source": [
    "#  df_today = test.loc[(test.reset_index()['date'] == d), :]\n",
    "print(np.shape(test))\n",
    "print(np.shape((test.reset_index()['date'] == d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "446"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.merge(run_list[0], run_list[1], how='outer')\n",
    "# test = run_list[0].reset_index()[['trial_idx', 'cell_idx', 'timestamp', 'trace_0']]\n",
    "len(np.unique(test.reset_index()['cell_idx']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.pivot_table(\n",
    "            index=['cell_idx'],\n",
    "            columns=['trial_idx', 'timestamp'], values='trace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.shape(test.values)\n",
    "pd.merge(run_list[0].head(), run_list[1].head(), how='outer', on='cell_idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## using old tensor algo rather than pandas df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for getting ids, ids_bool, and ids_sorter for number of consecutive days\n",
    "# count as driven if driven on any day\n",
    "def _group_drive_ids(days, dcs, drive_threshold):\n",
    "    \"\"\" \n",
    "    Get an array of all unique ids driven on any day for a given DaySorter.\n",
    "    \"\"\"\n",
    "    \n",
    "    good_ids = []\n",
    "    for day1 in days:\n",
    "    # get cell_ids\n",
    "        d1_ids = flow.xday._read_crossday_ids(day1.mouse, day1.date)\n",
    "        d1_ids = np.array([int(s) for s in d1_ids])\n",
    "\n",
    "        # filter cells based on visual/trial drive across all cs\n",
    "\n",
    "        d1_drive = []\n",
    "        for dcs in drive_css:\n",
    "            try:\n",
    "                d1_drive.append(pool.calc.driven.trial(day1, dcs))\n",
    "            except KeyError:\n",
    "                print(str(day1) + ' requested ' + dcs +\n",
    "                      ': no match to what was shown (probably pav only).')\n",
    "        d1_drive = np.max(d1_drive, axis=0)\n",
    "        d1_ids_bool = np.array(d1_drive) > drive_threshold\n",
    "        d1_drive_ids = d1_ids[np.array(d1_drive) > drive_threshold]\n",
    "        good_ids.extend(d1_drive_ids)\n",
    "\n",
    "    return np.unique(good_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCA parameters hashed: station\n"
     ]
    }
   ],
   "source": [
    "mouse='OA27'\n",
    "tags='naive'\n",
    "\n",
    "# TCA params\n",
    "rank=20\n",
    "method=('ncp_bcd',)\n",
    "replicates=3\n",
    "fit_options=None\n",
    "\n",
    "# grouping params\n",
    "group_by='naive'\n",
    "use_dprime=False\n",
    "\n",
    "# tensor params\n",
    "trace_type='zscore_day'\n",
    "cs=''\n",
    "downsample=True\n",
    "start_time=-1\n",
    "end_time=6\n",
    "clean_artifacts=None\n",
    "thresh=20\n",
    "warp=False\n",
    "smooth=True\n",
    "smooth_win=5\n",
    "verbose=True\n",
    "\n",
    "# filtering params\n",
    "exclude_tags=('disengaged', 'orientation_mapping', 'contrast', 'retinotopy', 'sated', 'learning_start')\n",
    "exclude_conds=('blank', 'blank_reward', 'pavlovian')\n",
    "driven=True\n",
    "drive_css=('0', '135', '270')\n",
    "drive_threshold=15\n",
    "\"\"\"\n",
    "Perform tensor component analysis (TCA) on data aligned\n",
    "across a group of days. Builds one large tensor.\n",
    "\n",
    "Algortitms from https://github.com/ahwillia/tensortools.\n",
    "\n",
    "Parameters\n",
    "-------\n",
    "methods, tuple of str\n",
    "    'cp_als', fits CP Decomposition using Alternating\n",
    "        Least Squares (ALS).\n",
    "    'ncp_bcd', fits nonnegative CP Decomposition using\n",
    "        the Block Coordinate Descent (BCD) Method.\n",
    "    'ncp_hals', fits nonnegtaive CP Decomposition using\n",
    "        the Hierarcial Alternating Least Squares\n",
    "        (HALS) Method.\n",
    "    'mcp_als', fits CP Decomposition with missing data using\n",
    "        Alternating Least Squares (ALS).\n",
    "\n",
    "rank, int\n",
    "    number of components you wish to fit\n",
    "\n",
    "replicates, int\n",
    "    number of initializations/iterations fitting for each rank\n",
    "\n",
    "Returns\n",
    "-------\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# create folder structure and save dir\n",
    "if fit_options is None:\n",
    "    fit_options = {'tol': 0.0001, 'max_iter': 500, 'verbose': False}\n",
    "pars = {'tags': tags, 'rank': rank, 'method': method,\n",
    "        'replicates': replicates, 'fit_options': fit_options,\n",
    "        'trace_type': trace_type, 'cs': cs, 'downsample': downsample,\n",
    "        'start_time': start_time, 'end_time': end_time,\n",
    "        'clean_artifacts': clean_artifacts, 'thresh': thresh,\n",
    "        'warp': warp, 'smooth': smooth, 'smooth_win': smooth_win,\n",
    "        'exclude_tags': exclude_tags, 'exclude_conds': exclude_conds,\n",
    "        'driven': driven, 'drive_css': drive_css,\n",
    "        'drive_threshold': drive_threshold}\n",
    "save_dir = paths.tca_path(mouse, 'group', pars=pars)\n",
    "\n",
    "days = flow.metadata.DateSorter.frommeta(mice=[mouse], tags=tags)\n",
    "\n",
    "meta_list = []\n",
    "tensor_list = []\n",
    "id_list = []\n",
    "for c, day1 in enumerate(days, 0):\n",
    "\n",
    "    # get cell_ids\n",
    "    d1_ids = flow.xday._read_crossday_ids(day1.mouse, day1.date)\n",
    "    d1_ids = np.array([int(s) for s in d1_ids])\n",
    "\n",
    "    # filter cells based on visual/trial drive across all cs\n",
    "#     d1_drive = np.max([pool.calc.driven.trial(day1, cs) for cs in drive_css], axis=0)\n",
    "\n",
    "    # filter cells based on visual/trial drive across all cs, prevent\n",
    "    # breaking when only pavs are shown\n",
    "    if driven:\n",
    "        good_ids = _group_drive_ids(days, dcs, drive_threshold)\n",
    "        d1_ids_bool = np.isin(d1_ids, good_ids)\n",
    "        d1_sorter = np.argsort(d1_ids[d1_ids_bool])\n",
    "    else:\n",
    "        d1_ids_bool = np.ones(np.shape(d1_ids)) > 0\n",
    "        d1_sorter = np.argsort(d1_ids[d1_ids_bool])\n",
    "    ids = d1_ids[d1_ids_bool][d1_sorter]\n",
    "\n",
    "    # TODO add in additional filter for being able to check for quality of xday alignment\n",
    "\n",
    "    # get all runs for both days\n",
    "    d1_runs = day1.runs()\n",
    "\n",
    "    # filter for only runs without certain tags\n",
    "    d1_runs = [run for run in d1_runs if not any(np.isin(run.tags, exclude_tags))]\n",
    "\n",
    "    # build tensors for all correct runs and trials after filtering\n",
    "    if d1_runs:\n",
    "        d1_tensor_list = []\n",
    "        d1_meta = []\n",
    "        for run in d1_runs:\n",
    "            t2p = run.trace2p()\n",
    "            # trigger all trials around stimulus onsets\n",
    "            run_traces = utils.getcstraces(run, cs=cs, trace_type=trace_type,\n",
    "                                     start_time=start_time, end_time=end_time,\n",
    "                                     downsample=True, clean_artifacts=clean_artifacts,\n",
    "                                     thresh=thresh, warp=warp, smooth=smooth,\n",
    "                                     smooth_win=smooth_win)\n",
    "            # filter and sort\n",
    "            run_traces = run_traces[d1_ids_bool, :, :][d1_sorter, :, :]\n",
    "            # get matched trial metadata/variables\n",
    "            dfr = tca._trialmetafromrun(run)\n",
    "            # subselect metadata if you are only running certain cs\n",
    "            if cs != '':\n",
    "                if cs == 'plus' or cs == 'minus' or cs == 'neutral':\n",
    "                    dfr = dfr.loc[(dfr['condition'].isin([cs])), :]\n",
    "                elif cs == '0' or cs == '135' or cs == '270':\n",
    "                    dfr = dfr.loc[(dfr['orientation'].isin([cs])), :]\n",
    "                else:\n",
    "                    print('ERROR: cs called - \"' + cs + '\" - is not\\\n",
    "                          a valid option.')\n",
    "\n",
    "            # subselect metadata to remove certain condtions\n",
    "            if len(exclude_conds) > 0:\n",
    "                dfr = dfr.loc[(~dfr['condition'].isin([exclude_conds])), :]\n",
    "\n",
    "            # drop trials with nans and add to lists\n",
    "            keep = np.sum(np.sum(np.isnan(run_traces), axis=0, keepdims=True),\n",
    "                          axis=1, keepdims=True).flatten() == 0\n",
    "            dfr = dfr.iloc[keep, :]\n",
    "            d1_tensor_list.append(run_traces[:, :, keep])\n",
    "            d1_meta.append(dfr)\n",
    "\n",
    "        # concatenate matched cells across trials 3rd dim (aka, 2)\n",
    "        tensor = np.concatenate(d1_tensor_list, axis=2)\n",
    "\n",
    "        # concatenate all trial metadata in pd dataframe\n",
    "        meta = pd.concat(d1_meta, axis=0)\n",
    "        \n",
    "    meta_list.append(meta)\n",
    "    tensor_list.append(tensor)\n",
    "    id_list.append(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   4,    6,    7,    9,   10,   13,   14,   17,   18,   19,   22,\n",
       "         23,   24,   25,   29,   30,   35,   39,   40,   41,   43,   44,\n",
       "         46,   48,   50,   51,   53,   54,   55,   56,   58,   60,   62,\n",
       "         64,   68,   71,   73,   76,   77,   79,   80,   82,   83,   84,\n",
       "         87,   90,   91,   92,   93,   95,   97,   98,   99,  103,  104,\n",
       "        106,  107,  108,  111,  113,  114,  116,  118,  119,  120,  121,\n",
       "        122,  123,  125,  126,  127,  129,  131,  133,  134,  135,  136,\n",
       "        137,  138,  139,  140,  141,  142,  144,  145,  147,  148,  149,\n",
       "        150,  152,  160,  161,  169,  170,  171,  172,  173,  175,  177,\n",
       "        178,  181,  182,  183,  186,  188,  189,  190,  191,  192,  194,\n",
       "        196,  197,  198,  200,  201,  202,  203,  204,  205,  208,  209,\n",
       "        210,  211,  213,  214,  216,  218,  220,  221,  222,  223,  224,\n",
       "        225,  226,  227,  229,  230,  233,  235,  236,  237,  238,  239,\n",
       "        240,  241,  243,  244,  245,  247,  248,  249,  250,  251,  255,\n",
       "        260,  262,  263,  265,  266,  270,  274,  276,  277,  279,  280,\n",
       "        281,  286,  287,  288,  290,  291,  293,  294,  295,  296,  298,\n",
       "        302,  308,  311,  313,  316,  318,  319,  320,  327,  329,  330,\n",
       "        332,  335,  336,  337,  344,  345,  346,  347,  351,  352,  353,\n",
       "        354,  357,  358,  360,  362,  363,  367,  371,  374,  376,  377,\n",
       "        378,  379,  382,  383,  388,  389,  398,  399,  401,  403,  404,\n",
       "        408,  409,  413,  414,  417,  418,  421,  422,  424,  427,  429,\n",
       "        450,  451,  473,  476,  481,  489,  491,  497,  508,  520,  528,\n",
       "        568,  601,  861,  879, 1111, 1294, 1438, 1506, 1554])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 155\n",
      "155 310\n",
      "310 465\n",
      "465 620\n"
     ]
    }
   ],
   "source": [
    "# get total trial number\n",
    "meta = pd.concat(meta_list, axis=0)\n",
    "trial_num = len(meta.reset_index()['trial_idx'])\n",
    "\n",
    "# use ids to get union of ids. Use these for indexing and adding tensor together\n",
    "id_union = np.unique(np.concatenate(id_list, axis=0))\n",
    "cell_num = len(id_union)\n",
    "\n",
    "# preallocate\n",
    "trial_start = 0\n",
    "trial_end = 0\n",
    "group_tensor = np.zeros((cell_num, np.shape(tensor_list[0])[1], trial_num))\n",
    "group_tensor[:] = np.nan\n",
    "for i in range(len(tensor_list)):\n",
    "    trial_end += np.shape(tensor_list[i])[2]\n",
    "    print(trial_start, trial_end)\n",
    "    for c, k in enumerate(id_list[i]):\n",
    "        celln_all_trials = tensor_list[i][c, :, :]\n",
    "#         print(np.shape(celln_all_trials))\n",
    "        group_tensor[(id_union == k), :, trial_start:trial_end] = celln_all_trials\n",
    "    trial_start += np.shape(tensor_list[i])[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(251, 108, 620)\n",
      "(139, 108, 155)\n",
      "(128, 108, 155)\n",
      "(108, 108, 155)\n",
      "(108, 108, 155)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(group_tensor))\n",
    "for i in range(len(tensor_list)):\n",
    "    print(np.shape(tensor_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'None'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
