{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouped TCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensortools as tt\n",
    "import numpy as np\n",
    "import flow\n",
    "from flow.misc import wordhash\n",
    "import pool\n",
    "import pandas as pd\n",
    "import os\n",
    "from cascade import utils\n",
    "from cascade import paths\n",
    "from cascade import tca\n",
    "from copy import deepcopy\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse='OA27'\n",
    "tags='naive'\n",
    "run_type='training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = flow.metadata.RunSorter.frommeta(mice=[mouse], run_types=run_type, tags=tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Run(mouse='OA27', date=170116, run=3, run_type='training', tags=('hungry', 'kelly', 'naive')),\n",
       " Run(mouse='OA27', date=170118, run=3, run_type='training', tags=('hungry', 'kelly', 'naive')),\n",
       " Run(mouse='OA27', date=170119, run=1, run_type='training', tags=('hungry', 'kelly', 'naive'))]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs[0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "44.0\n",
      "1491.0\n"
     ]
    }
   ],
   "source": [
    "# days = flow.metadata.DateSorter.frommeta(mice=[mouse], tags=tags)\n",
    "\n",
    "# # maybe use a run sorter?\n",
    "\n",
    "# dprime pool.calc.behavior.dprime(day1)\n",
    "# pool.calc.driven.trial(day1, dcs)\n",
    "run_list = []\n",
    "for c, run in enumerate(runs[0:-1]):\n",
    "    dfr = tca._triggerfromrun(run)\n",
    "#     dfr = dfr.reset_index()[['trial_idx', 'cell_idx', 'timestamp', 'trace']]\n",
    "#     dfr.rename(columns={'trace': 'trace_' + str(c)}, inplace=True)\n",
    "    run_list.append(dfr)\n",
    "dfr = pd.concat(run_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>trace</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mouse</th>\n",
       "      <th>date</th>\n",
       "      <th>run</th>\n",
       "      <th>trial_idx</th>\n",
       "      <th>cell_idx</th>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">OA27</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">170116</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">3</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>-1.0</th>\n",
       "      <td>-0.078952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>-1.0</th>\n",
       "      <td>-0.024965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>-1.0</th>\n",
       "      <td>0.057309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>-1.0</th>\n",
       "      <td>-0.248164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>-1.0</th>\n",
       "      <td>0.101081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  trace\n",
       "mouse date   run trial_idx cell_idx timestamp          \n",
       "OA27  170116 3   0.0       1.0      -1.0      -0.078952\n",
       "                 1.0       1.0      -1.0      -0.024965\n",
       "                 2.0       1.0      -1.0       0.057309\n",
       "                 3.0       1.0      -1.0      -0.248164\n",
       "                 4.0       1.0      -1.0       0.101081"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build list of cells with their ids and then do an outer merge of the dataframes\n",
    "times = len(np.unique(dfr.reset_index()['timestamp']))\n",
    "test = dfr.pivot_table(\n",
    "            index=['date', 'run', 'cell_idx'],\n",
    "            columns=['trial_idx', 'timestamp'], values='trace')\n",
    "\n",
    "for d in np.unique(test.reset_index()['date']):\n",
    "    keep = np.where((test.reset_index()['date'] == d) == True)[0]\n",
    "    df_today = test.iloc[keep, :]\n",
    "    for r in np.unique(df_today.reset_index()['run']):\n",
    "        keep2 = np.where((df_today.reset_index()['run'] == r) == True)[0]\n",
    "        df_run = df_today.iloc[keep2, :]\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(264, 16816)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(times)\n",
    "mat = df_run.values\n",
    "np.shape(mat)\n",
    "# np.shape(df_run.values.reshape((np.shape(df_run)[0], times, -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(754, 16816)\n",
      "(754,)\n"
     ]
    }
   ],
   "source": [
    "#  df_today = test.loc[(test.reset_index()['date'] == d), :]\n",
    "print(np.shape(test))\n",
    "print(np.shape((test.reset_index()['date'] == d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "446"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.merge(run_list[0], run_list[1], how='outer')\n",
    "# test = run_list[0].reset_index()[['trial_idx', 'cell_idx', 'timestamp', 'trace_0']]\n",
    "len(np.unique(test.reset_index()['cell_idx']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.pivot_table(\n",
    "            index=['cell_idx'],\n",
    "            columns=['trial_idx', 'timestamp'], values='trace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.shape(test.values)\n",
    "pd.merge(run_list[0].head(), run_list[1].head(), how='outer', on='cell_idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## using old tensor algo rather than pandas df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse='OA27'\n",
    "tags=None\n",
    "\n",
    "# TCA params\n",
    "rank=20\n",
    "method=('ncp_bcd',)\n",
    "replicates=3\n",
    "fit_options=None\n",
    "\n",
    "# grouping params\n",
    "group_by='naive'\n",
    "use_dprime=False\n",
    "\n",
    "# tensor params\n",
    "trace_type='zscore_day'\n",
    "cs=''\n",
    "downsample=True\n",
    "start_time=-1\n",
    "end_time=6\n",
    "clean_artifacts=None\n",
    "thresh=20\n",
    "warp=False\n",
    "smooth=True\n",
    "smooth_win=5\n",
    "verbose=True\n",
    "\n",
    "# filtering params\n",
    "exclude_tags=('disengaged', 'orientation_mapping', 'contrast', 'retinotopy', 'sated')\n",
    "exclude_conds=('blank', 'blank_reward', 'pavlovian')\n",
    "driven=True\n",
    "drive_css=('0', '135', '270')\n",
    "drive_threshold=15\n",
    "\"\"\"\n",
    "Perform tensor component analysis (TCA) on data aligned\n",
    "across a group of days. Builds one large tensor.\n",
    "\n",
    "Algortitms from https://github.com/ahwillia/tensortools.\n",
    "\n",
    "Parameters\n",
    "-------\n",
    "methods, tuple of str\n",
    "    'cp_als', fits CP Decomposition using Alternating\n",
    "        Least Squares (ALS).\n",
    "    'ncp_bcd', fits nonnegative CP Decomposition using\n",
    "        the Block Coordinate Descent (BCD) Method.\n",
    "    'ncp_hals', fits nonnegtaive CP Decomposition using\n",
    "        the Hierarcial Alternating Least Squares\n",
    "        (HALS) Method.\n",
    "    'mcp_als', fits CP Decomposition with missing data using\n",
    "        Alternating Least Squares (ALS).\n",
    "\n",
    "rank, int\n",
    "    number of components you wish to fit\n",
    "\n",
    "replicates, int\n",
    "    number of initializations/iterations fitting for each rank\n",
    "\n",
    "Returns\n",
    "-------\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# create folder structure and save dir\n",
    "if fit_options is None:\n",
    "    fit_options = {'tol': 0.0001, 'max_iter': 500, 'verbose': False}\n",
    "pars = {'tags': tags, 'rank': rank, 'method': method,\n",
    "        'replicates': replicates, 'fit_options': fit_options,\n",
    "        'trace_type': trace_type, 'cs': cs, 'downsample': downsample,\n",
    "        'start_time': start_time, 'end_time': end_time,\n",
    "        'clean_artifacts': clean_artifacts, 'thresh': thresh,\n",
    "        'warp': warp, 'smooth': smooth, 'smooth_win': smooth_win,\n",
    "        'exclude_tags': exclude_tags, 'exclude_conds': exclude_conds,\n",
    "        'driven': driven, 'drive_css': drive_css,\n",
    "        'drive_threshold': drive_threshold}\n",
    "save_dir = paths.tca_path(mouse, 'group', pars=pars)\n",
    "\n",
    "days = flow.metadata.DateSorter.frommeta(mice=[mouse], tags=tags)\n",
    "\n",
    "meta_list = []\n",
    "tensor_list = []\n",
    "id_list = []\n",
    "for c, day1 in enumerate(days, 0):\n",
    "\n",
    "    # get cell_ids\n",
    "    d1_ids = flow.xday._read_crossday_ids(day1.mouse, day1.date)\n",
    "    d1_ids = np.array([int(s) for s in d1_ids])\n",
    "\n",
    "    # filter cells based on visual/trial drive across all cs\n",
    "#     d1_drive = np.max([pool.calc.driven.trial(day1, cs) for cs in drive_css], axis=0)\n",
    "\n",
    "    # filter cells based on visual/trial drive across all cs, prevent\n",
    "    # breaking when only pavs are shown\n",
    "    if driven:\n",
    "        d1_drive = []\n",
    "        for dcs in drive_css:\n",
    "            try:\n",
    "                d1_drive.append(pool.calc.driven.trial(day1, dcs))\n",
    "            except KeyError:\n",
    "                print(str(day1) + ' requested ' + dcs +\n",
    "                      ': no match to what was shown (probably pav only).')\n",
    "        d1_drive = np.max(d1_drive, axis=0)\n",
    "        # account for rare cases where lost xday ids are final id (making _ids\n",
    "        # 1 shorter than _drive). Add a fake id to the end and force drive to\n",
    "        # be false for that id\n",
    "        if len(d1_drive) > len(d1_ids):\n",
    "            print('Warning: ' + str(day1) + ': _ids was ' +\n",
    "                  str(len(d1_drive)-len(d1_ids)) +\n",
    "                  ' shorter than _drive: added pseudo-id.')\n",
    "            d1_drive[-1] = 0\n",
    "            d1_ids = np.concatenate((d1_ids, np.array([-1])))\n",
    "        d1_ids_bool = np.array(d1_drive) > drive_threshold\n",
    "        d1_drive_ids = d1_ids[np.array(d1_drive) > drive_threshold]\n",
    "        d1_sorter = np.argsort(d1_ids[d1_ids_bool])\n",
    "    else:\n",
    "        d1_ids_bool = np.ones(np.shape(d1_ids)) > 0\n",
    "        d1_sorter = np.argsort(d1_ids[d1_ids_bool])\n",
    "    ids = d1_ids[d1_ids_bool][d1_sorter]\n",
    "\n",
    "    # TODO add in additional filter for being able to check for quality of xday alignment\n",
    "\n",
    "    # get all runs for both days\n",
    "    d1_runs = day1.runs()\n",
    "\n",
    "    # filter for only runs without certain tags\n",
    "    d1_runs = [run for run in d1_runs if not any(np.isin(run.tags, exclude_tags))]\n",
    "\n",
    "    # build tensors for all correct runs and trials after filtering\n",
    "    if d1_runs:\n",
    "        d1_tensor_list = []\n",
    "        d1_meta = []\n",
    "        for run in d1_runs:\n",
    "            t2p = run.trace2p()\n",
    "            # trigger all trials around stimulus onsets\n",
    "            run_traces = utils.getcstraces(run, cs=cs, trace_type=trace_type,\n",
    "                                     start_time=start_time, end_time=end_time,\n",
    "                                     downsample=True, clean_artifacts=clean_artifacts,\n",
    "                                     thresh=thresh, warp=warp, smooth=smooth,\n",
    "                                     smooth_win=smooth_win)\n",
    "            # filter and sort\n",
    "            run_traces = run_traces[d1_ids_bool, :, :][d1_sorter, :, :]\n",
    "            # get matched trial metadata/variables\n",
    "            dfr = _trialmetafromrun(run)\n",
    "            # subselect metadata if you are only running certain cs\n",
    "            if cs != '':\n",
    "                if cs == 'plus' or cs == 'minus' or cs == 'neutral':\n",
    "                    dfr = dfr.loc[(dfr['condition'].isin([cs])), :]\n",
    "                elif cs == '0' or cs == '135' or cs == '270':\n",
    "                    dfr = dfr.loc[(dfr['orientation'].isin([cs])), :]\n",
    "                else:\n",
    "                    print('ERROR: cs called - \"' + cs + '\" - is not\\\n",
    "                          a valid option.')\n",
    "\n",
    "            # subselect metadata to remove certain condtions\n",
    "            if len(exclude_conds) > 0:\n",
    "                dfr = dfr.loc[(~dfr['condition'].isin([exclude_conds])), :]\n",
    "\n",
    "            # drop trials with nans and add to lists\n",
    "            keep = np.sum(np.sum(np.isnan(run_traces), axis=0, keepdims=True),\n",
    "                          axis=1, keepdims=True).flatten() == 0\n",
    "            dfr = dfr.iloc[keep, :]\n",
    "            d1_tensor_list.append(run_traces[:, :, keep])\n",
    "            d1_meta.append(dfr)\n",
    "\n",
    "        # concatenate matched cells across trials 3rd dim (aka, 2)\n",
    "        tensor = np.concatenate(d1_tensor_list, axis=2)\n",
    "\n",
    "        # concatenate all trial metadata in pd dataframe\n",
    "        meta = pd.concat(d1_meta, axis=0)\n",
    "        \n",
    "    meta_list.append(meta)\n",
    "    tensor_list.append(tensors)\n",
    "    id_list.append(ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
