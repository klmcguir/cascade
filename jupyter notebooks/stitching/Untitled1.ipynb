{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensortools as tt\n",
    "import numpy as np\n",
    "import flow\n",
    "from flow.misc import wordhash\n",
    "import pool\n",
    "import pandas as pd\n",
    "import os\n",
    "from cascade import utils\n",
    "from cascade import paths\n",
    "from cascade import tca\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse='OA27'\n",
    "tags=None\n",
    "\n",
    "# TCA params\n",
    "rank=20\n",
    "method=('ncp_bcd',)\n",
    "replicates=3\n",
    "fit_options=None\n",
    "\n",
    "# grouping params\n",
    "group_by='all'\n",
    "up_or_down='up'\n",
    "use_dprime=False\n",
    "dprime_threshold=2\n",
    "\n",
    "# tensor params\n",
    "trace_type='zscore_day'\n",
    "cs=''\n",
    "downsample=True\n",
    "start_time=-1\n",
    "end_time=6\n",
    "clean_artifacts=None\n",
    "thresh=20\n",
    "warp=False\n",
    "smooth=True\n",
    "smooth_win=5\n",
    "nan_trial_threshold=None\n",
    "verbose=True\n",
    "\n",
    "# filtering params\n",
    "exclude_tags=('disengaged', 'orientation_mapping', 'contrast', 'retinotopy', 'sated')\n",
    "exclude_conds=('blank', 'blank_reward', 'pavlovian')\n",
    "driven=True\n",
    "drive_css=('0', '135', '270')\n",
    "drive_threshold=15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCA parameters hashed: rochester\n",
      "Recalcing pool.calc.zscore.mu: OA27 170206 \n",
      "Recalcing pool.calc.zscore.sigma: OA27 170206 \n",
      "Recalcing pool.calc.zscore.mu: OA27 170207 \n",
      "Recalcing pool.calc.zscore.sigma: OA27 170207 \n",
      "Recalcing pool.calc.zscore.mu: OA27 170208 \n",
      "Recalcing pool.calc.zscore.sigma: OA27 170208 \n",
      "Recalcing pool.calc.zscore.mu: OA27 170209 \n",
      "Recalcing pool.calc.zscore.sigma: OA27 170209 \n",
      "Recalcing pool.calc.zscore.mu: OA27 170210 \n",
      "Recalcing pool.calc.zscore.sigma: OA27 170210 \n",
      "Recalcing pool.calc.zscore.mu: OA27 170211 \n",
      "Recalcing pool.calc.zscore.sigma: OA27 170211 \n",
      "Recalcing pool.calc.zscore.mu: OA27 170214 \n",
      "Recalcing pool.calc.zscore.sigma: OA27 170214 \n",
      "Recalcing pool.calc.zscore.mu: OA27 170215 \n",
      "Recalcing pool.calc.zscore.sigma: OA27 170215 \n",
      "Recalcing pool.calc.zscore.mu: OA27 170216 \n",
      "Recalcing pool.calc.zscore.sigma: OA27 170216 \n",
      "Recalcing pool.calc.zscore.mu: OA27 170320 \n",
      "Recalcing pool.calc.zscore.sigma: OA27 170320 \n",
      "Tensor decomp about to begin: tensor shape = (994, 108, 9073)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Perform tensor component analysis (TCA) on data aligned\n",
    "across a group of days. Builds one large tensor.\n",
    "\n",
    "Algorithms from https://github.com/ahwillia/tensortools.\n",
    "\n",
    "Parameters\n",
    "-------\n",
    "methods, tuple of str\n",
    "    'cp_als', fits CP Decomposition using Alternating\n",
    "        Least Squares (ALS).\n",
    "    'ncp_bcd', fits nonnegative CP Decomposition using\n",
    "        the Block Coordinate Descent (BCD) Method.\n",
    "    'ncp_hals', fits nonnegative CP Decomposition using\n",
    "        the Hierarchical Alternating Least Squares\n",
    "        (HALS) Method.\n",
    "    'mcp_als', fits CP Decomposition with missing data using\n",
    "        Alternating Least Squares (ALS).\n",
    "\n",
    "rank, int\n",
    "    number of components you wish to fit\n",
    "\n",
    "replicates, int\n",
    "    number of initializations/iterations fitting for each rank\n",
    "\n",
    "Returns\n",
    "-------\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# set grouping parameters\n",
    "if group_by.lower() == 'naive':\n",
    "    tags = 'naive'\n",
    "    use_dprime = False\n",
    "    exclude_tags = ('disengaged', 'orientation_mapping', 'contrast',\n",
    "                    'retinotopy', 'sated', 'learning_start')\n",
    "\n",
    "elif group_by.lower() == 'high_dprime_learning':\n",
    "    use_dprime = True\n",
    "    up_or_down = 'up'\n",
    "    tags = 'learning'\n",
    "    exclude_tags = ('disengaged', 'orientation_mapping', 'contrast',\n",
    "                    'retinotopy', 'sated', 'learning_start',\n",
    "                    'reversal1_start')\n",
    "\n",
    "elif group_by.lower() == 'low_dprime_leanrning':\n",
    "    use_dprime = True\n",
    "    up_or_down = 'down'\n",
    "    tags = 'learning'\n",
    "    exclude_tags = ('disengaged', 'orientation_mapping', 'contrast',\n",
    "                    'retinotopy', 'sated', 'learning_start')\n",
    "\n",
    "elif group_by.lower() == 'high_dprime_reversal1':\n",
    "    use_dprime = True\n",
    "    up_or_down = 'up'\n",
    "    tags = 'reversal1'\n",
    "    exclude_tags = ('disengaged', 'orientation_mapping', 'contrast',\n",
    "                    'retinotopy', 'sated', 'reversal2_start')\n",
    "\n",
    "elif group_by.lower() == 'low_dprime_reversal1':\n",
    "    use_dprime = True\n",
    "    up_or_down = 'down'\n",
    "    tags = 'reversal1'\n",
    "    exclude_tags = ('disengaged', 'orientation_mapping', 'contrast',\n",
    "                    'retinotopy', 'sated')\n",
    "\n",
    "elif group_by.lower() == 'high_dprime_reversal2':\n",
    "    use_dprime = True\n",
    "    up_or_down = 'up'\n",
    "    tags = 'reversal2'\n",
    "    exclude_tags = ('disengaged', 'orientation_mapping', 'contrast',\n",
    "                    'retinotopy', 'sated')\n",
    "\n",
    "elif group_by.lower() == 'low_dprime_reversal2':\n",
    "    use_dprime = True\n",
    "    up_or_down = 'down'\n",
    "    tags = 'reversal2'\n",
    "    exclude_tags = ('disengaged', 'orientation_mapping', 'contrast',\n",
    "                    'retinotopy', 'sated')\n",
    "\n",
    "elif group_by.lower() == 'naive_vs_high_dprime':\n",
    "    use_dprime = True\n",
    "    up_or_down = 'up'\n",
    "    tags = None\n",
    "    days = flow.DateSorter.frommeta(mice=[mouse], tags='naive')\n",
    "    days.extend(flow.DateSorter.frommeta(mice=[mouse], tags='learning'))\n",
    "    dates = set(days)\n",
    "    exclude_tags = ('disengaged', 'orientation_mapping', 'contrast',\n",
    "                    'retinotopy', 'sated', 'learning_start',\n",
    "                    'reversal1_start')\n",
    "\n",
    "elif group_by.lower() == 'l_vs_r1':  # high dprime\n",
    "    use_dprime = True\n",
    "    up_or_down = 'up'\n",
    "    tags = None\n",
    "    days = flow.DateSorter.frommeta(mice=[mouse], tags='learning')\n",
    "    days.extend(flow.DateSorter.frommeta(mice=[mouse], tags='reversal1'))\n",
    "    dates = set(days)\n",
    "    exclude_tags = ('disengaged', 'orientation_mapping', 'contrast',\n",
    "                    'retinotopy', 'sated', 'learning_start',\n",
    "                    'reversal1_start')\n",
    "\n",
    "elif group_by.lower() == 'all':\n",
    "    tags = None\n",
    "    use_dprime = False\n",
    "    exclude_tags = ('disengaged', 'orientation_mapping', 'contrast',\n",
    "                    'retinotopy', 'sated', 'learning_start',\n",
    "                    'reversal1_start', 'reversal2_start')\n",
    "\n",
    "else:\n",
    "    print('Using input parameters without modification by group_by=...')\n",
    "\n",
    "# create folder structure and save dir\n",
    "if fit_options is None:\n",
    "    fit_options = {'tol': 0.0001, 'max_iter': 500, 'verbose': False}\n",
    "pars = {'tags': tags, 'rank': rank, 'method': method,\n",
    "        'replicates': replicates, 'fit_options': fit_options,\n",
    "        'trace_type': trace_type, 'cs': cs, 'downsample': downsample,\n",
    "        'start_time': start_time, 'end_time': end_time,\n",
    "        'clean_artifacts': clean_artifacts, 'thresh': thresh,\n",
    "        'warp': warp, 'smooth': smooth, 'smooth_win': smooth_win,\n",
    "        'exclude_tags': exclude_tags, 'exclude_conds': exclude_conds,\n",
    "        'driven': driven, 'drive_css': drive_css,\n",
    "        'drive_threshold': drive_threshold}\n",
    "group_pars = {'group_by': group_by, 'up_or_down': up_or_down,\n",
    "              'use_dprime': use_dprime,\n",
    "              'dprime_threshold': dprime_threshold}\n",
    "save_dir = paths.tca_path(mouse, 'group', pars=pars, group_pars=group_pars)\n",
    "\n",
    "# get DateSorter object\n",
    "if np.isin(group_by.lower(), ['naive_vs_high_dprime', 'l_vs_r1']):\n",
    "    days = flow.DateSorter(dates=dates)\n",
    "else:\n",
    "    days = flow.DateSorter.frommeta(mice=[mouse], tags=tags)\n",
    "\n",
    "# filter DateSorter object if you are filtering on dprime\n",
    "if use_dprime:\n",
    "    dprime = []\n",
    "    for day1 in days:\n",
    "        # for comparison with naive make sure dprime keeps naive days\n",
    "        if np.isin('naive', day1.tags):\n",
    "            if up_or_down.lower() == 'up':\n",
    "                dprime.append(np.inf)\n",
    "            else:\n",
    "                dprime.append(-np.inf)\n",
    "        else:\n",
    "            dprime.append(pool.calc.performance.dprime(day1))\n",
    "    if up_or_down.lower() == 'up':\n",
    "        days = [d for c, d in enumerate(days) if dprime[c]\n",
    "                > dprime_threshold]\n",
    "    elif up_or_down.lower() == 'down':\n",
    "        days = [d for c, d in enumerate(days) if dprime[c]\n",
    "                <= dprime_threshold]\n",
    "\n",
    "# preallocate for looping over a group of days/runs\n",
    "meta_list = []\n",
    "tensor_list = []\n",
    "id_list = []\n",
    "for c, day1 in enumerate(days, 0):\n",
    "\n",
    "# c = 10\n",
    "# da1 = days[c]\n",
    "\n",
    "    # get cell_ids\n",
    "    d1_ids = flow.xday._read_crossday_ids(day1.mouse, day1.date)\n",
    "    d1_ids = np.array([int(s) for s in d1_ids])\n",
    "\n",
    "    # filter cells based on visual/trial drive across all cs, prevent\n",
    "    # breaking when only pavs are shown\n",
    "    if driven:\n",
    "        good_ids = tca._group_drive_ids(days, drive_css, drive_threshold)\n",
    "        d1_ids_bool = np.isin(d1_ids, good_ids)\n",
    "        d1_sorter = np.argsort(d1_ids[d1_ids_bool])\n",
    "    else:\n",
    "        d1_ids_bool = np.ones(np.shape(d1_ids)) > 0\n",
    "        d1_sorter = np.argsort(d1_ids[d1_ids_bool])\n",
    "    ids = d1_ids[d1_ids_bool][d1_sorter]\n",
    "\n",
    "    # TODO add in additional filter for being able to check for quality of xday alignment\n",
    "\n",
    "    # get all runs for both days\n",
    "    d1_runs = day1.runs()\n",
    "\n",
    "    # filter for only runs without certain tags\n",
    "    d1_runs = [run for run in d1_runs if not\n",
    "               any(np.isin(run.tags, exclude_tags))]\n",
    "\n",
    "    # build tensors for all correct runs and trials after filtering\n",
    "    if d1_runs:\n",
    "        d1_tensor_list = []\n",
    "        d1_meta = []\n",
    "        for run in d1_runs:\n",
    "            t2p = run.trace2p()\n",
    "            # trigger all trials around stimulus onsets\n",
    "            run_traces = utils.getcstraces(\n",
    "                run, cs=cs, trace_type=trace_type,\n",
    "                start_time=start_time, end_time=end_time,\n",
    "                downsample=True, clean_artifacts=clean_artifacts,\n",
    "                thresh=thresh, warp=warp, smooth=smooth,\n",
    "                smooth_win=smooth_win)\n",
    "            # filter and sort\n",
    "            run_traces = run_traces[d1_ids_bool, :, :][d1_sorter, :, :]\n",
    "            # get matched trial metadata/variables\n",
    "            dfr = tca._trialmetafromrun(run)\n",
    "            # subselect metadata if you are only running certain cs\n",
    "            if cs != '':\n",
    "                if cs == 'plus' or cs == 'minus' or cs == 'neutral':\n",
    "                    dfr = dfr.loc[(dfr['condition'].isin([cs])), :]\n",
    "                elif cs == '0' or cs == '135' or cs == '270':\n",
    "                    dfr = dfr.loc[(dfr['orientation'].isin([cs])), :]\n",
    "                else:\n",
    "                    print('ERROR: cs called - \"' + cs + '\" - is not\\\n",
    "                          a valid option.')\n",
    "\n",
    "            # subselect metadata to remove certain conditions\n",
    "            if len(exclude_conds) > 0:\n",
    "                run_traces = run_traces[:,:,(~dfr['condition'].isin(exclude_conds))]\n",
    "                dfr = dfr.loc[(~dfr['condition'].isin(exclude_conds)), :]\n",
    "\n",
    "            # drop trials with nans and add to lists\n",
    "            keep = np.sum(np.sum(np.isnan(run_traces), axis=0,\n",
    "                           keepdims=True),\n",
    "                           axis=1, keepdims=True).flatten() == 0\n",
    "            dfr = dfr.iloc[keep, :]\n",
    "            d1_tensor_list.append(run_traces[:, :, keep])\n",
    "            d1_meta.append(dfr)\n",
    "\n",
    "        # concatenate matched cells across trials 3rd dim (aka, 2)\n",
    "        tensor = np.concatenate(d1_tensor_list, axis=2)\n",
    "\n",
    "        # concatenate all trial metadata in pd dataframe\n",
    "        meta = pd.concat(d1_meta, axis=0)\n",
    "\n",
    "        meta_list.append(meta)\n",
    "        tensor_list.append(tensor)\n",
    "        id_list.append(ids)\n",
    "\n",
    "# get total trial number across all days/runs\n",
    "meta = pd.concat(meta_list, axis=0)\n",
    "trial_num = len(meta.reset_index()['trial_idx'])\n",
    "\n",
    "# get union of ids. Use these for indexing and splicing tensors together\n",
    "id_union = np.unique(np.concatenate(id_list, axis=0))\n",
    "cell_num = len(id_union)\n",
    "\n",
    "# build a single large tensor leaving zeros where cell is not found\n",
    "trial_start = 0\n",
    "trial_end = 0\n",
    "group_tensor = np.zeros((cell_num, np.shape(tensor_list[0])[1], trial_num))\n",
    "group_tensor[:] = np.nan\n",
    "for i in range(len(tensor_list)):\n",
    "    trial_end += np.shape(tensor_list[i])[2]\n",
    "    for c, k in enumerate(id_list[i]):\n",
    "        celln_all_trials = tensor_list[i][c, :, :]\n",
    "        group_tensor[(id_union == k), :, trial_start:trial_end] = celln_all_trials\n",
    "    trial_start += np.shape(tensor_list[i])[2]\n",
    "\n",
    "# allow for cells with low number of trials to be dropped\n",
    "if nan_trial_threshold:\n",
    "    # update saving tag\n",
    "    nt_tag = '_nantrial' + str(nan_trial_threshold)\n",
    "    # remove cells with too many nan trials\n",
    "    ntrials = np.shape(group_tensor)[2]\n",
    "    nbadtrials = np.sum(np.isnan(group_tensor[:, 0, :]), 1)\n",
    "    badtrialratio = nbadtrials/ntrials\n",
    "    badcell_indexer = badtrialratio < nan_trial_threshold\n",
    "    group_tensor = group_tensor[badcell_indexer, :, :]\n",
    "    if verbose:\n",
    "        print('Removed ' + str(np.sum(~badcell_indexer)) +\n",
    "              ' cells from tensor:' + ' badtrialratio < ' +\n",
    "              str(nan_trial_threshold))\n",
    "        print('Kept ' + str(np.sum(badcell_indexer)) +\n",
    "              ' cells from tensor:' + ' badtrialratio < ' +\n",
    "              str(nan_trial_threshold))\n",
    "else:\n",
    "    nt_tag = ''\n",
    "\n",
    "# just so you have a clue how big the tensor is\n",
    "if verbose:\n",
    "    print('Tensor decomp about to begin: tensor shape = '\n",
    "          + str(np.shape(group_tensor)))\n",
    "\n",
    "# # concatenate and save df for the day\n",
    "# meta_path = os.path.join(\n",
    "#     save_dir, str(day1.mouse) + '_' + str(group_by) + nt_tag +\n",
    "#     '_df_group_meta.pkl')\n",
    "# input_tensor_path = os.path.join(\n",
    "#     save_dir, str(day1.mouse) + '_' + str(group_by) + nt_tag +\n",
    "#     '_group_tensor_' + str(trace_type) + '.npy')\n",
    "# input_ids_path = os.path.join(\n",
    "#     save_dir, str(day1.mouse) + '_' + str(group_by) + nt_tag +\n",
    "#     '_group_ids_' + str(trace_type) + '.npy')\n",
    "# output_tensor_path = os.path.join(\n",
    "#     save_dir, str(day1.mouse) + '_' + str(group_by) + nt_tag +\n",
    "#     '_group_decomp_' + str(trace_type) + '.npy')\n",
    "# meta.to_pickle(meta_path)\n",
    "# np.save(input_tensor_path, group_tensor)\n",
    "# np.save(input_ids_path, id_union)\n",
    "\n",
    "# # run TCA - iterate over different fitting methods\n",
    "# if np.isin('mcp_als', method):\n",
    "#     mask = np.ones((cell_num, np.shape(tensor_list[0])[1], trial_num))\n",
    "#     mask[np.isnan(group_tensor)] = 0\n",
    "#     group_tensor[np.isnan(group_tensor)] = 0\n",
    "#     ensemble = {}\n",
    "#     results = {}\n",
    "#     for m in method:\n",
    "#         for r in range(1, rank+1):\n",
    "#             results[r] = [tt.mcp_als(group_tensor, r, mask, **fit_options)]\n",
    "#             print('mcp_als: rank ' + str(r) + ' complete.')\n",
    "#         ensemble[m] = lambda: None\n",
    "#         ensemble[m].results = results\n",
    "#     np.save(output_tensor_path, ensemble)\n",
    "# else:\n",
    "#     ensemble = {}\n",
    "#     group_tensor[np.isnan(group_tensor)] = 0\n",
    "#     for m in method:\n",
    "#         ensemble[m] = tt.Ensemble(\n",
    "#             fit_method=m, fit_options=deepcopy(fit_options))\n",
    "#         ensemble[m].fit(group_tensor, ranks=range(1, rank+1),\n",
    "#                         replicates=replicates, verbose=False)\n",
    "#     np.save(output_tensor_path, ensemble)\n",
    "\n",
    "# # print output so you don't go crazy waiting\n",
    "# if verbose:\n",
    "#     print(str(day1.mouse) + ': group_by=' + str(group_by) + ': done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()\n",
    "test3 = dfr.loc[(~dfr['condition'].isin(exclude_conds)), :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(217, 108, 156)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(run_traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2p.ntrials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.13545571, -0.55725071, -0.00861827, ...,  0.09508422,\n",
       "          0.58916331, -0.40673721],\n",
       "        [ 0.39357157, -0.60746333,  0.04384792, ...,  0.43967123,\n",
       "          0.44959684, -0.04714625],\n",
       "        [ 0.44397417,  0.23089005, -0.01845654, ..., -0.04410947,\n",
       "         -0.2791574 ,  0.31364191],\n",
       "        ...,\n",
       "        [ 0.20672533,  0.16921419, -0.01751344, ...,  0.12758494,\n",
       "          0.33895173,  0.53191529],\n",
       "        [ 0.03415234, -0.21527571, -0.24497716, ..., -0.3632924 ,\n",
       "          0.20256687,  0.07392191],\n",
       "        [-0.41423693, -0.11474283, -0.52239691, ..., -0.24943832,\n",
       "          0.05720108, -0.46533179]],\n",
       "\n",
       "       [[-0.36720286, -0.55381454,  0.72293383, ..., -0.01617902,\n",
       "          0.00686328, -0.065801  ],\n",
       "        [-0.44264966, -0.70489139,  1.17066645, ...,  0.16161317,\n",
       "          0.04875797, -0.11962567],\n",
       "        [-0.44054114, -0.37664435,  0.46303564, ..., -0.07735421,\n",
       "          0.09382399, -0.05691464],\n",
       "        ...,\n",
       "        [-0.37775604, -0.10172   , -1.42200799, ..., -0.57396068,\n",
       "         -0.06127777,  0.22910375],\n",
       "        [-0.20410563, -0.09140392, -1.49769728, ..., -0.82877945,\n",
       "         -0.02933522,  0.06203832],\n",
       "        [-0.11196349, -0.15830282, -1.65146369, ..., -0.64109724,\n",
       "          0.1666603 , -0.13885928]],\n",
       "\n",
       "       [[-0.01773425, -0.44671008, -0.18730016, ...,  0.42562294,\n",
       "          0.79495811,  0.26037471],\n",
       "        [-0.14053382, -0.28901479, -0.1268183 , ...,  0.41403841,\n",
       "          0.27551096,  0.20960069],\n",
       "        [-0.08324336,  0.06948335, -0.08644416, ...,  0.18375723,\n",
       "         -0.12717563,  0.12142826],\n",
       "        ...,\n",
       "        [ 0.11126477,  0.46780239, -0.4812357 , ...,  0.26600408,\n",
       "         -2.43108663,  0.41559364],\n",
       "        [-0.18085158,  0.17063881, -0.36526029, ...,  0.63802074,\n",
       "         -1.96304594,  0.39972049],\n",
       "        [-0.36678972,  0.18111344, -0.30224791, ...,  0.72598204,\n",
       "         -2.10811915,  0.44428997]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.03123743, -0.23944383, -0.27977012, ..., -0.08568184,\n",
       "         -0.02148869,  0.09861813],\n",
       "        [-0.24171071, -0.2297837 ,  0.10971625, ...,  0.4590138 ,\n",
       "         -0.20515667,  0.1677188 ],\n",
       "        [-0.01893134,  0.36905674, -0.23341642, ...,  0.17768891,\n",
       "         -0.34502416,  0.01366886],\n",
       "        ...,\n",
       "        [-0.22654518, -0.07933376, -0.5806836 , ..., -0.50985926,\n",
       "          0.10678515,  1.01741739],\n",
       "        [-0.05647052, -0.20225062,  0.27635047, ..., -0.6087961 ,\n",
       "         -0.00925219,  0.62737884],\n",
       "        [ 1.12197664, -0.2593261 ,  0.5156939 , ..., -0.01219373,\n",
       "          0.02139846,  0.55744953]],\n",
       "\n",
       "       [[-0.49520249,  0.09435242, -0.12221618, ..., -2.60504658,\n",
       "          0.24463064, -0.18129753],\n",
       "        [-0.34631745,  0.09523976,  0.12249315, ..., -2.41340964,\n",
       "         -0.0211581 , -0.09683492],\n",
       "        [ 0.06272773,  0.03462742,  0.3704478 , ..., -2.36704262,\n",
       "         -0.11672351, -0.00583038],\n",
       "        ...,\n",
       "        [-0.49860946, -0.1566711 ,  0.21183892, ..., -2.95473315,\n",
       "         -0.1486418 ,  0.26309809],\n",
       "        [-0.47717888, -0.47690538, -0.04789387, ..., -2.85428049,\n",
       "         -0.1637446 ,  0.12283091],\n",
       "        [-0.23608284, -0.62875626,  0.01562597, ..., -2.39340704,\n",
       "          0.20117059, -0.13778426]],\n",
       "\n",
       "       [[ 0.10211497,  0.12560666,  0.33286621, ..., -0.04285108,\n",
       "          0.26036736,  0.52083528],\n",
       "        [-0.35171163, -0.20078449,  0.59191949, ...,  0.42726388,\n",
       "          0.35629238,  0.70327303],\n",
       "        [-0.38035697, -0.0376692 ,  0.32758062, ...,  0.01244018,\n",
       "         -0.55711867, -0.1950413 ],\n",
       "        ...,\n",
       "        [ 0.42180272, -0.20273108, -0.3665364 , ..., -0.13651564,\n",
       "          0.19694747,  0.60595071],\n",
       "        [-0.29617894, -0.76510876, -0.30545663, ...,  0.01169053,\n",
       "          0.05647423,  0.34635055],\n",
       "        [-0.22648445, -0.54824744,  0.04184345, ...,  0.09788912,\n",
       "          0.04628336, -0.3032058 ]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_traces[:,:,(~dfr['condition'].isin(exclude_conds))]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
