{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import flow\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "import cascade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [cell_idx, timestamp, trace, orientation, condition, trialerror, hunger, learning_state, tag, firstlick, ensure, quinine, speed]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "mouse = 'OA26'\n",
    "trace_type = 'zscore'\n",
    "cell_id = [417]\n",
    "\n",
    "# load metadata\n",
    "save_dir = os.path.join(flow.paths.outd, str(mouse))\n",
    "meta_path = os.path.join(save_dir, str(mouse) + '_df_trialmeta.pkl')\n",
    "dfm = pd.read_pickle(meta_path)\n",
    "\n",
    "# create a binary map of every day a cell is present\n",
    "xmap = cascade.df.get_xdaymap(mouse)\n",
    "\n",
    "# set up range conditonal on input\n",
    "if cell_id is None:\n",
    "    cell_range = range(1, np.shape(xmap)[0]+1)\n",
    "else:\n",
    "    cell_range = cell_id\n",
    "\n",
    "# loop through cells and plot\n",
    "for cell_idx in cell_range:\n",
    "\n",
    "    # create single cell df\n",
    "    dft = cascade.df.singlecell(mouse, trace_type, cell_idx, xmap=xmap)\n",
    "    dft = dft.reset_index(level=['cell_idx', 'timestamp'])\n",
    "\n",
    "    # filter metadata trials before merging\n",
    "    trial_indexer = (((dfm.orientation == 0) | (dfm.orientation == 135) | (dfm.orientation == 270))\n",
    "                     & ((dfm.tag == 'standard') | (dfm.tag == 'learning_start') | (dfm.tag == 'reversal1_start')\n",
    "                     | (dfm.tag == 'reversal2_start'))\n",
    "                     & ((dfm.condition == 'plus') | (dfm.condition == 'minus') | (dfm.condition == 'neutral'))\n",
    "                     & (dfm.hunger == 'hungry'))\n",
    "    dfm = dfm.loc[trial_indexer, :]\n",
    "\n",
    "    # merge on filtered trials\n",
    "    dff = pd.merge(dft, dfm, on=['mouse', 'date', 'run', 'trial_idx'], how='inner')\n",
    "\n",
    "    print(dff.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff.empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(301, 216, 176)\n",
      "216\n",
      "108.0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-958909a9b268>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;31m# downsample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mds_traces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtrial\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_traces\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "mouse = 'OA26'\n",
    "trace_type = 'dff'\n",
    "start_time = -1\n",
    "end_time = 6\n",
    "downsample = True\n",
    "verbose = True\n",
    "\n",
    "# build your runs object\n",
    "dates = flow.metadata.DateSorter.frommeta(mice=[mouse])\n",
    "\n",
    "trial_list = []\n",
    "count = 1\n",
    "# loop through all days for a mouse, build and save pandas df\n",
    "for d in dates:\n",
    "\n",
    "    # loop through runs on a particular day\n",
    "    for run in d.runs():\n",
    "\n",
    "        # get your t2p object\n",
    "        t2p = run.trace2p()\n",
    "\n",
    "        # get your cell# from xday alignment\n",
    "        # use to index along axis=0 in cstraces/run_traces\n",
    "        cell_ids = flow.xday._read_crossday_ids(run.mouse, run.date)\n",
    "        cell_ids = [int(s) for s in cell_ids]\n",
    "\n",
    "        # trigger all trials around stimulus onsets\n",
    "        run_traces = t2p.cstraces('', start_s=start_time, end_s=end_time,\n",
    "                                  trace_type=trace_type, cutoff_before_lick_ms=-1,\n",
    "                                  errortrials=-1, baseline=(0, -1),\n",
    "                                  baseline_to_stimulus=True)\n",
    "\n",
    "        # downsample all traces/timestamps to 15Hz if framerate is 31Hz\n",
    "        if (t2p.d['framerate'] > 30) and downsample:\n",
    "\n",
    "            # make sure divisible by 2\n",
    "            sz = np.shape(run_traces)  # dims: (cells, time, trials)\n",
    "            if sz[1] % 2 == 1:\n",
    "                run_traces = run_traces[:, :-1, :]\n",
    "                sz = np.shape(run_traces)\n",
    "            print(sz)\n",
    "            print(sz[1])\n",
    "            print(sz[1]/2)\n",
    "            # downsample\n",
    "            ds_traces = np.zeros((sz[0], sz[1]/2, sz[2]))\n",
    "            for trial in range(sz[2]):\n",
    "                a = run_traces[:, :, trial].reshape(sz[0], sz[1]/2, 2)\n",
    "                ds_traces[:, :, trial] = np.nanmean(a, axis=2)\n",
    "\n",
    "            run_traces = ds_traces\n",
    "\n",
    "        # make timestamps, downsample is necessary\n",
    "        timestep = 1/t2p.d['framerate']\n",
    "        timestamps = np.arange(start_time, end_time, timestep)\n",
    "\n",
    "        if (t2p.d['framerate'] > 30) and downsample:\n",
    "            timestamps = timestamps[::2][:np.shape(run_traces)[1]]\n",
    "\n",
    "        # check that you don't have extra cells\n",
    "        if len(cell_ids) != np.shape(run_traces)[0]:\n",
    "            run_traces = run_traces[range(0,len(cell_ids)), :, :]\n",
    "            warnings.warn(str(run) + ': You have more cell traces than cell_idx: skipping extra cells.')\n",
    "\n",
    "        # build matrices to match cell, trial, time variables to traces\n",
    "        trial_mat = np.ones(np.shape(run_traces))\n",
    "        for trial in range(np.shape(run_traces)[2]):\n",
    "            trial_mat[:, :, trial] = trial\n",
    "\n",
    "        cell_mat = np.ones(np.shape(run_traces))\n",
    "        for cell in range(np.shape(run_traces)[0]):\n",
    "            cell_mat[cell, :, :] = cell_ids[cell]\n",
    "\n",
    "        time_mat = np.ones(np.shape(run_traces))\n",
    "        for timept in range(np.shape(run_traces)[1]):\n",
    "            time_mat[:, timept, :] = timestamps[timept]\n",
    "\n",
    "        # reshape and build df\n",
    "        vec_sz = run_traces.size\n",
    "        index = pd.MultiIndex.from_arrays([\n",
    "            [run.mouse] * vec_sz,\n",
    "            [run.date] * vec_sz,\n",
    "            [run.run] * vec_sz,\n",
    "            trial_mat.reshape(vec_sz),\n",
    "            cell_mat.reshape(vec_sz),\n",
    "            time_mat.reshape(vec_sz)\n",
    "            ],\n",
    "            names=['mouse', 'date', 'run', 'trial_idx',\n",
    "                   'cell_idx', 'timestamp'])\n",
    "\n",
    "        # append all runs across a day together in a list\n",
    "        trial_list.append(pd.DataFrame({'trace': run_traces.reshape(vec_sz)}, index=index))\n",
    "\n",
    "        # clear your t2p to save memory\n",
    "        run._t2p = None\n",
    "\n",
    "    # create folder structure if needed\n",
    "#     save_dir = os.path.join(flow.paths.outd, str(mouse))\n",
    "#     if not os.path.isdir(save_dir):\n",
    "#         os.mkdir(save_dir)\n",
    "#     save_dir = os.path.join(save_dir, 'dfs ' + str(trace_type))\n",
    "#     if not os.path.isdir(save_dir):\n",
    "#         os.mkdir(save_dir)\n",
    "\n",
    "#     # concatenate and save df for the day\n",
    "#     trial_df = pd.concat(trial_list, axis=0)\n",
    "#     save_path = os.path.join(save_dir, str(d.mouse) + '_' + str(d.date)\n",
    "#                              + '_df_' + trace_type + '.pkl')\n",
    "#     trial_df.to_pickle(save_path)\n",
    "\n",
    "#     # print output so you don't go crazy waiting\n",
    "#     if verbose:\n",
    "#         print('Day: ' + str(count) + ': ' + str(d.mouse)\n",
    "#               + '_' + str(d.date) + ': ' + str(len(trial_list)))\n",
    "#         count = count + 1\n",
    "\n",
    "#     # reset trial list before starting new day\n",
    "#     trial_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{17: 'orientation_0', 18: 'orientation_45', 19: 'orientation_90', 20: 'orientation_135', 21: 'orientation_180', 22: 'orientation_225', 23: 'orientation_270', 24: 'orientation_315'}\n",
      "[24 19 23 19 22 17 20 21 21 17 18 22 23 18 20 24 24 21 18 20 23 19 24 19\n",
      " 22 23 17 17 20 21 18 22 20 23 24 21 22 20 21 19 24 18 18 19 17 23 17 22\n",
      " 18 17 20 22 19 17 20 19 21 18 24 23 24 21 22 23 19 22 20 23 22 18 23 24\n",
      " 18 24 21 20 19 21 17 17 18 24 21 19 23 17 17 21 20 23 22 18 24 22 20 19\n",
      " 19 19 20 21 22 18 17 17 24 20 22 23 21 18 24 23 21 21 18 19 23 20 22 20\n",
      " 24 19 23 17 17 18 22 24 23 22 24 17 19 22 21 23 20 24 18 20 19 17 18 21\n",
      " 21 20 23 18 23 22 18 17 24 21 20 17 24 22 19 19 23 17 17 20 19 21 22 18\n",
      " 23 24 24 20 21 19 22 18 17 17 20 19 24 20 21 22 22 19 21 18 18 23 24 23\n",
      " 23 24 20 17 22 21 21 22 17 23 18 24 19 19 20 18 18 24 23 23 18 19 19 20\n",
      " 20 17 22 21]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-137adbb057aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mlookup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt2p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'codes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m  \u001b[0;31m# invert dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlookup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrial_conds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m     \u001b[0mt2p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'condition'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrial_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt2p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'codes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "mouse = 'OA27'\n",
    "trace_type = 'dff'\n",
    "start_time = -1\n",
    "end_time = 6\n",
    "downsample = True\n",
    "verbose = True\n",
    "\n",
    "runs = flow.metadata.RunSorter.frommeta(mice=[mouse])\n",
    "\n",
    "# triggering parameters\n",
    "start_time = start_time\n",
    "end_time = end_time\n",
    "trace_type = trace_type\n",
    "\n",
    "trial_list = []\n",
    "for run in runs:\n",
    "\n",
    "    # get your t2p object\n",
    "    t2p = run.trace2p()\n",
    "\n",
    "    # trigger all trials around stimulus onsets to get trial number\n",
    "    run_traces = t2p.cstraces('', start_s=start_time, end_s=end_time, trace_type=trace_type,\n",
    "                    cutoff_before_lick_ms=-1, errortrials=-1, baseline=(0, -1),\n",
    "                    baseline_to_stimulus=True)\n",
    "    trial_idx = range(np.shape(run_traces)[2])\n",
    "\n",
    "    # get your learning_state\n",
    "    run_tags = [str(s) for s in run.tags]\n",
    "    run_tags = run.tags\n",
    "    if 'naive' in run_tags:\n",
    "        learning_state = 'naive'\n",
    "    elif 'learning' in run_tags:\n",
    "        learning_state = 'learning'\n",
    "    elif 'reversal1' in run_tags:\n",
    "        learning_state = 'reversal1'\n",
    "    elif 'reversal2' in run_tags:\n",
    "        learning_state = 'reversal2'  \n",
    "    learning_state = [learning_state]*len(trial_idx)\n",
    "\n",
    "    # get hunger state for all trials, consider hungry if not sated\n",
    "    if 'sated' in run_tags:\n",
    "        hunger = 'sated'\n",
    "    else:\n",
    "        hunger = 'hungry'\n",
    "    hunger = [hunger]*len(trial_idx)\n",
    "\n",
    "    # get relevant trial-distinguising tags excluding kelly, hunger-state, and learning-state\n",
    "    tags = [str(run_tags[s]) for s in range(len(run_tags)) if run_tags[s] != hunger[0]\n",
    "            and run_tags[s] != learning_state[0]\n",
    "            and run_tags[s] != 'kelly'\n",
    "            and run_tags[s] != 'learning_start'\n",
    "            and run_tags[s] != 'reversal1_start'\n",
    "            and run_tags[s] != 'reversal2_start']\n",
    "    if tags == []:  # define as \"standard\" if the run is not another option\n",
    "        tags = ['standard']\n",
    "    tags = [tags[0]]*len(trial_idx)\n",
    "\n",
    "    # get trialerror ensureing you don't include runthrough at end of trials\n",
    "    trialerror = np.array(t2p.d['trialerror'][trial_idx])\n",
    "\n",
    "    # get cs and orientation infor for each trial\n",
    "#     oris = []\n",
    "#     css = []\n",
    "#     print(t2p.d['codes'].items())\n",
    "#     print(t2p.d['orientations'].items())\n",
    "#     for trial in t2p.d['condition'][trial_idx]:\n",
    "#         # get cs and ori\n",
    "#         print(trial)\n",
    "    lookup = dict([v,k] for k,v in t2p.d['codes'].items())\n",
    "    print(lookup)\n",
    "#             if v == trial:\n",
    "#                 print(v)\n",
    "#                 print(k)\n",
    "#                 print(t2p.d['orientations'][k])\n",
    "#                 css.append(k)\n",
    "#                 oris.append(t2p.d['orientations'][k])\n",
    "#         codename = t2p.d['codes'].keys()[t2p.d['codes'].values().index(trial)]\n",
    "#         codename = t2p.d['codes'].keys()[t2p.d['codes'].values()[trial]]\n",
    "#         oriname = t2p.d['orientations'][codename]\n",
    "#         css.append(codename)\n",
    "#         oris.append(oriname)\n",
    "\n",
    "    oris = []\n",
    "    css = []\n",
    "#     lookup = dict([v,k] for k,v in t2p.d['codes'].items())\n",
    "#     print(lookup)\n",
    "#     lookup = {t2p.d['codes'][key]:key for key in t2p.d['codes']}\n",
    "#     print(lookup)\n",
    "#     lookup = {v:k for k,v in t2p.d['codes'].items()}\n",
    "#     print(lookup)\n",
    "    \n",
    "    trial_conds = t2p.d['condition'][trial_idx]\n",
    "    print(trial_conds)\n",
    "    lookup = {v:k for k,v in t2p.d['codes'].items()}  # invert dict \n",
    "    css = [lookup[s] for s in t2p.d['condition'][trial_idx]]\n",
    "    oris = [lookup[s] for s in t2p.d['orientations'][trial_idx]]\n",
    "    print(lookup[trial_conds])\n",
    "    t2p.d['condition'][trial_idx]\n",
    "    print(t2p.d['codes'].items())\n",
    "    print(t2p.d['orientations'].items())\n",
    "    for trial in t2p.d['condition'][trial_idx]:\n",
    "        # get cs and ori\n",
    "        try: # python 3\n",
    "            codename = list(t2p.d['codes'].keys())[list(t2p.d['codes'].values()).index(trial)]\n",
    "        except: # python 2\n",
    "            codename = t2p.d['codes'].keys()[t2p.d['codes'].values().index(trial)]\n",
    "        oriname = t2p.d['orientations'][codename]\n",
    "        css.append(codename)\n",
    "        oris.append(oriname)\n",
    "        \n",
    "#         print(trial, codename, oriname)\n",
    "\n",
    "#     # get mean running speed for time stim is on screen\n",
    "#     all_onsets = t2p.csonsets()\n",
    "#     all_offsets = t2p.d['offsets'][0:len(all_onsets)]\n",
    "#     if t2p.d['running'].size > 0:\n",
    "#         speed_vec = t2p.speed()\n",
    "#         speed_vec = speed_vec.astype('float')\n",
    "#         speed = []\n",
    "#         for s in trial_idx:\n",
    "#             try:\n",
    "#                 speed.append(np.nanmean(speed_vec[all_onsets[s]:all_offsets[s]]))\n",
    "#             except:\n",
    "#                 speed.append(np.nan)\n",
    "#         speed = np.array(speed)\n",
    "#     else:\n",
    "#         speed = np.full(len(trial_idx), np.nan)\n",
    "\n",
    "#     # get offset relative to triggered data\n",
    "# #     offsets = all_offsets - all_onsets + (np.abs(start_time)*np.round(t2p.d['framerate']))\n",
    "# #     offsets = offsets.flatten()\n",
    "\n",
    "#     # get ensure/ensure/firstlick relative to triggered data\n",
    "#     ensure = t2p.ensure()\n",
    "#     ensure = ensure.astype('float')\n",
    "#     ensure[ensure == 0] = np.nan\n",
    "#     ensure = ensure - all_onsets + (np.abs(start_time)*np.round(t2p.d['framerate']))\n",
    "\n",
    "#     quinine = t2p.quinine()\n",
    "#     quinine = quinine.astype('float')\n",
    "#     quinine[quinine == 0] = np.nan\n",
    "#     quinine = quinine - all_onsets + (np.abs(start_time)*np.round(t2p.d['framerate']))\n",
    "\n",
    "#     firstlick = t2p.firstlick('')[trial_idx]\n",
    "#     firstlick = firstlick + (np.abs(start_time)*np.round(t2p.d['framerate']))\n",
    "\n",
    "#     # downsample all timestamps to 15Hz if framerate is 31Hz\n",
    "#     if (t2p.d['framerate'] > 30) and downsample:\n",
    "#         ensure = ensure/2\n",
    "#         quinine = quinine/2\n",
    "#         firstlick = firstlick/2\n",
    "\n",
    "#     # create your index out of relevant variables\n",
    "#     index = pd.MultiIndex.from_arrays([\n",
    "#                 [run.mouse]*len(trial_idx),\n",
    "#                 [run.date]*len(trial_idx),\n",
    "#                 [run.run]*len(trial_idx),\n",
    "#                 trial_idx\n",
    "#                 ],\n",
    "#                 names=['mouse', 'date', 'run', 'trial_idx'])\n",
    "\n",
    "#     data = {'orientation':  oris, 'condition': css,\n",
    "#             'trialerror': trialerror, 'hunger': hunger,\n",
    "#             'learning_state': learning_state, 'tag': tags,\n",
    "#             'firstlick': firstlick, 'ensure': ensure,\n",
    "#             'quinine': quinine, 'speed': speed}\n",
    "\n",
    "#     # append all trials across all runs together into a list\n",
    "#     trial_list.append(pd.DataFrame(data, index=index))\n",
    "\n",
    "#     # clear your t2p to save RAM\n",
    "#     run._t2p = None\n",
    "#     if verbose:\n",
    "#         print('Run: ' + str(run) + ': ' + str(len(trial_list)))\n",
    "\n",
    "# # concatenate all runs together in final dataframe\n",
    "# trial_df = pd.concat(trial_list, axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
